{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Goal\n",
      "- implement the gradient-based learning using sampling\n",
      "- implement the EM method\n",
      "- compare the two using synthetic data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "Our goal in this exercise is to learn the parameters of a model from incomplete data. The model is a mixture of Guassians. According to this model, each data point is sampled from one of $C$ Gaussian distributions, according to the class of that data point. The prior probability for class label follows a multinomial distribution:\n",
      "\n",
      "\\begin{equation}\n",
      "P(Z_i = j) = p_j \n",
      "\\end{equation}\n",
      "\n",
      "Given the class of a data point, its value follows a normal distribution with parameters that are specific to that class:\n",
      "\n",
      "\\begin{equation}\n",
      "P(Y_i = y | Z_i = j) = N(y; \\mu_j, \\sigma_j)\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sampling the latent variables\n",
      "For each data point $Y_i$ we have:\n",
      "\n",
      "\\begin{align*}\n",
      "P(Z_i=j|Y_i=y_i;\\Theta) & \\propto P(Y_i=y_i|Z_i=j;\\Theta)P(Z_i=j;\\Theta)   \\\\\n",
      "                  & = N(y_i;\\mu_j,\\sigma_j) \\cdot p_j\n",
      "\\end{align*}\n",
      "\n",
      "Having the posterior of class label, we can sample the label from this posterior:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "from numpy.random import multinomial\n",
      "\n",
      "# returns a vector with counts of each class\n",
      "def sample_label(parameters, y, num_samples=1):\n",
      "    multinomial_parameters, normal_parameters = parameters\n",
      "    assert len(multinomial_parameters) == len(normal_parameters)\n",
      "    num_classes = len(multinomial_parameters)\n",
      "    \n",
      "    posterior = [0.0] * num_classes\n",
      "    for i in range(num_classes):\n",
      "        mu, sigma = normal_parameters[i]\n",
      "        p = multinomial_parameters[i]\n",
      "        posterior[i] = norm.pdf(y, loc=mu, scale=sigma) * p\n",
      "    s = sum(posterior)\n",
      "    posterior = [ps/s for ps in posterior]\n",
      "    return multinomial(num_samples, posterior)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## TODO: Check the correctness of this statement!\n",
      "\n",
      "Let us test the correctness of gradients of normal distribution. Given $f(x, \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{\\frac{(x-\\mu)^2}{2\\sigma^2}}$, I believe that:\n",
      "\\begin{align}\n",
      "\\frac{\\partial f}{\\partial \\mu} &= f . \\frac{1}{\\sigma} . \\big(\\frac{x-\\mu}{\\sigma}\\big) \\\\\n",
      "\\frac{\\partial f}{\\partial \\sigma} &= f . \\frac{1}{\\sigma} . \\big( (\\frac{x-\\mu}{\\sigma})^2 -1 \\big)\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import check_grad\n",
      "from scipy.stats import norm\n",
      "from numpy.random import random_sample, normal\n",
      "\n",
      "def f_normal(x):\n",
      "    def _f(inp):\n",
      "        mu, sigma = inp\n",
      "        return norm.pdf(x, loc=mu, scale=sigma)\n",
      "    return _f\n",
      "\n",
      "def fprime_normal(x):\n",
      "    def _fprime(inp):\n",
      "        f_val = f(x)(inp)\n",
      "        mu, sigma = inp\n",
      "        xms = (x-mu)/sigma\n",
      "        \n",
      "        grad=[0.0]*2\n",
      "        grad[0] = f_val/sigma * xms\n",
      "        grad[1] = f_val/sigma * (xms**2 - 1)\n",
      "        return grad\n",
      "    return _fprime\n",
      "\n",
      "# for i in range(10000):\n",
      "#     mu = 30 * random_sample()\n",
      "#     sigma = 10 * random_sample()\n",
      "#     val = normal(mu, sigma)\n",
      "#     diff =  check_grad(f(val), fprime(val), [mu, sigma])\n",
      "#     if diff > 1e-4:\n",
      "#         print mu, sigma, val, diff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy.random import dirichlet, multinomial\n",
      "import numpy\n",
      "\n",
      "def f_multinomial(label):\n",
      "    def _f_multinomial(parameters):\n",
      "        \"\"\"Return the function and gradient of multinomial distribution\n",
      "        \"\"\"\n",
      "        assert label < len(parameters)\n",
      "        f = parameters[label]/sum(parameters)\n",
      "        return f\n",
      "    return _f_multinomial\n",
      "\n",
      "def fprime_multinomial(label):\n",
      "    def _fprime_multinomial(parameters):\n",
      "        \"\"\"Return the function and gradient of multinomial distribution\n",
      "        \"\"\"\n",
      "        assert label < len(parameters)\n",
      "        s = sum(parameters)\n",
      "        s_rest = s - parameters[label]\n",
      "        f = f_multinomial(label)(parameters)\n",
      "        fprime = [-params[label]/(s**2)] * len(parameters)\n",
      "        fprime[label] = s_rest/(s**2)\n",
      "        return fprime\n",
      "    return _fprime_multinomial\n",
      "\n",
      "# num_classes = 20 \n",
      "# for i in range(10000):\n",
      "#     params = dirichlet(tuple([1.0]*num_classes))\n",
      "#     val = multinomial(1, params)\n",
      "#     val = numpy.where(val==1)[0][0]\n",
      "#     diff =  check_grad(f_multinomial(val), fprime_multinomial(val), params)\n",
      "#     if diff > 1e-4:\n",
      "#         print params, val, diff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy.random import normal\n",
      "\n",
      "def f_multinomial_pos(label):\n",
      "    def _f_multinomial(parameters):\n",
      "        \"\"\"Return the function and gradient of multinomial distribution\n",
      "        \"\"\"\n",
      "        assert label < len(parameters)\n",
      "        f = parameters[label]/sum(parameters)\n",
      "        return f\n",
      "    def _f_multinomial_pos(parameters):\n",
      "        parameters = numpy.exp(parameters)\n",
      "        return _f_multinomial(parameters)\n",
      "    return _f_multinomial_pos\n",
      "\n",
      "def fprime_multinomial_pos(label):\n",
      "    def _fprime_multinomial(parameters):\n",
      "        \"\"\"Return the function and gradient of multinomial distribution\n",
      "        \"\"\"\n",
      "        assert label < len(parameters)\n",
      "        s = sum(parameters)\n",
      "        s_rest = s - parameters[label]\n",
      "        f = f_multinomial(label)(parameters)\n",
      "        fprime = [-params[label]/(s**2)] * len(parameters)\n",
      "        fprime[label] = s_rest/(s**2)\n",
      "        return fprime\n",
      "    def _fprime_multinomial_pos(parameters):\n",
      "        parameters = numpy.exp(parameters)\n",
      "        return parameters * _fprime_multinomial(parameters)\n",
      "    return _fprime_multinomial_pos\n",
      "\n",
      "# num_classes = 3\n",
      "# for i in range(10):\n",
      "#     params = [normal(loc=0, scale=1) for i in range(num_classes)]\n",
      "#     p2 = numpy.exp(params)\n",
      "#     p2 = [i/sum(p2) for i in p2]\n",
      "#     print p2\n",
      "#     val = multinomial(1, p2)\n",
      "#     val = numpy.where(val==1)[0][0]\n",
      "#     diff =  check_grad(f_multinomial_pos(val), fprime_multinomial_pos(val), params)\n",
      "#     if diff > 1e-4:\n",
      "#         print params, val, diff\n",
      "#         print f_multinomial_pos(val)(params), fprime_multinomial_pos(val)(params)\n",
      "\n",
      "from scipy.optimize import approx_fprime\n",
      "val = 0 \n",
      "params = [-0.1714175342344088, -0.9057264122117221, 0.15583792310504577]\n",
      "print approx_fprime(params, f_multinomial_pos(val), 1.49e-08)\n",
      "print fprime_multinomial_pos(val)(params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.22713782 -0.05837683 -0.16876098]\n",
        "[ 0.22713781  0.01187795  0.03433784]\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Approximating the gradient\n",
      "The log likelihood of data point $i$ can be written as $L(\\Theta) = \\log P(Y_i, Z_i;\\Theta)$. \n",
      "So the gradient of log-likelihood function can be written as:\n",
      "\n",
      "\\begin{equation}\n",
      "\\partial_{\\Theta} L(\\Theta) = \n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ll(parameters, values):\n",
      "    \"\"\"Compute the likelihood and its gradients.\n",
      "    \n",
      "    arguments:\n",
      "    parameters -- current value of parameters\n",
      "    values     -- values for all random variables\n",
      "    \"\"\"\n",
      "    \n",
      "    return likelihood, gradients\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [1, 0, -1]\n",
      "numpy.exp(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "array([ 2.71828183,  1.        ,  0.36787944])"
       ]
      }
     ],
     "prompt_number": 49
    }
   ],
   "metadata": {}
  }
 ]
}