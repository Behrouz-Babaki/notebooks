{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "- implement the gradient-based learning using sampling\n",
    "- implement the EM method\n",
    "- compare the two using synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Our goal in this exercise is to learn the parameters of a model from incomplete data. The model is a mixture of Guassians. According to this model, each data point is sampled from one of $C$ Gaussian distributions, according to the class of that data point. The prior probability for class label follows a multinomial distribution:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Z_i = j) = p_j \n",
    "\\end{equation}\n",
    "\n",
    "Given the class of a data point, its value follows a normal distribution with parameters that are specific to that class:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Y_i = y | Z_i = j) = N(y; \\mu_j, \\sigma_j)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the latent variables\n",
    "For each data point $Y_i$ we have:\n",
    "\n",
    "\\begin{align*}\n",
    "P(Z_i=j|Y_i=y_i;\\Theta) & \\propto P(Y_i=y_i|Z_i=j;\\Theta)P(Z_i=j;\\Theta)   \\\\\n",
    "                  & = N(y_i;\\mu_j,\\sigma_j) \\cdot p_j\n",
    "\\end{align*}\n",
    "\n",
    "Having the posterior of class label, we can sample the label from this posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from numpy.random import multinomial\n",
    "\n",
    "# returns a vector with counts of each class\n",
    "def sample_label(parameters, y, num_samples=1):\n",
    "    multinomial_parameters, normal_parameters = parameters\n",
    "    assert len(multinomial_parameters) == len(normal_parameters)\n",
    "    num_classes = len(multinomial_parameters)\n",
    "    \n",
    "    posterior = [0.0] * num_classes\n",
    "    for i in range(num_classes):\n",
    "        mu, sigma = normal_parameters[i]\n",
    "        p = multinomial_parameters[i]\n",
    "        posterior[i] = norm.pdf(y, loc=mu, scale=sigma) * p\n",
    "    s = sum(posterior)\n",
    "    posterior = [ps/s for ps in posterior]\n",
    "    return multinomial(num_samples, posterior)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us test the correctness of gradients of normal distribution. Given $f(x, \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{\\frac{(x-\\mu)^2}{2\\sigma^2}}$, I believe that:\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial \\mu} &= f . \\frac{1}{\\sigma} . \\big(\\frac{x-\\mu}{\\sigma}\\big) \\\\\n",
    "\\frac{\\partial f}{\\partial \\sigma} &= f . \\frac{1}{\\sigma} . \\big( (\\frac{x-\\mu}{\\sigma})^2 -1 \\big)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import check_grad\n",
    "from scipy.stats import norm\n",
    "from numpy.random import random_sample, normal\n",
    "\n",
    "def f_normal(x):\n",
    "    def _f(inp):\n",
    "        mu, sigma = inp\n",
    "        return norm.pdf(x, loc=mu, scale=sigma)\n",
    "    return _f\n",
    "\n",
    "def fprime_normal(x):\n",
    "    def _fprime(inp):\n",
    "        f_val = f(x)(inp)\n",
    "        mu, sigma = inp\n",
    "        xms = (x-mu)/sigma\n",
    "        \n",
    "        grad=[0.0]*2\n",
    "        grad[0] = f_val/sigma * xms\n",
    "        grad[1] = f_val/sigma * (xms**2 - 1)\n",
    "        return grad\n",
    "    return _fprime\n",
    "\n",
    "# for i in range(10000):\n",
    "#     mu = 30 * random_sample()\n",
    "#     sigma = 10 * random_sample()\n",
    "#     val = normal(mu, sigma)\n",
    "#     diff =  check_grad(f(val), fprime(val), [mu, sigma])\n",
    "#     if diff > 1e-4:\n",
    "#         print mu, sigma, val, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2928469665 0.00592172043732 28.2863311113 0.000598214503615\n",
      "8.96909573673 0.000621093559227 8.96901323197 0.0266009950405\n",
      "28.1549881946 0.0068173659069 28.1529651645 0.000199039264796\n",
      "9.80309539067 0.00749007908259 9.81579395677 0.00102107474286\n",
      "19.9941297072 0.00911564481845 19.9917446729 0.00011452526983\n",
      "25.5092916176 0.0221553537523 25.4729479686 0.000108410052508\n",
      "27.9116999558 0.00186872685539 27.9092031722 0.00953395716171\n",
      "10.0643932165 0.00784502673061 10.0624190567 0.000155770172607\n",
      "29.1572354162 0.00705287246878 29.1434574364 0.00157213412558\n",
      "2.32903647632 0.00168510148118 2.32796070813 0.0026881099904\n",
      "7.45309686299 0.01909445103 7.41427392373 0.000233930416804\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random_sample, normal\n",
    "from scipy.stats import norm\n",
    "\n",
    "def f_normal_log(x):\n",
    "    return lambda y : norm.logpdf(x, loc=y[0], scale=y[1])\n",
    "\n",
    "def fprime_normal_log(x):\n",
    "    def fprime_log_(y):\n",
    "        mu, sigma = y\n",
    "        xms = (x-mu)/sigma\n",
    "        fprime_mu = xms / sigma\n",
    "        fprime_sigma = (xms**2 - 1) / sigma\n",
    "        return (fprime_mu, fprime_sigma)\n",
    "    return fprime_log_\n",
    "\n",
    "for i in range(5000):\n",
    "    mu = 30 * random_sample()\n",
    "    sigma = 10 * random_sample()\n",
    "    val = normal(mu, sigma)\n",
    "    diff =  check_grad(f_normal_log(val), fprime_normal_log(val), [mu, sigma])\n",
    "    if diff > 1e-4:\n",
    "        print mu, sigma, val, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_multinomial(f_multinomial_pos, fprime_multinomial_pos, \n",
    "                    num_tests = 1000):\n",
    "    num_classes = np.random.randint(40)\n",
    "    for i in range(num_tests):\n",
    "        params = [normal(loc=0, scale=1) for i in range(num_classes)]\n",
    "        p2 = numpy.exp(params)\n",
    "        p2 = [i/sum(p2) for i in p2]\n",
    "        val = multinomial(1, p2)\n",
    "        val = numpy.where(val==1)[0][0]\n",
    "        diff =  check_grad(f_multinomial_pos(val), fprime_multinomial_pos(val), params)\n",
    "        if diff > 1e-4:\n",
    "            print params, val, diff\n",
    "            print f_multinomial_pos(val)(params) \n",
    "            print fprime_multinomial_pos(val)(params)\n",
    "            print approx_fprime(params, f_multinomial_pos(val), 1.49e-08)\n",
    "            print \n",
    "    print 'test finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test finished\n"
     ]
    }
   ],
   "source": [
    "def f_multinomial_pos(label):\n",
    "    return (lambda parameters : np.exp(parameters[label]) / sum(np.exp(parameters)))\n",
    "\n",
    "def fprime_multinomial_pos(label):\n",
    "    def _fprime_multinomial_pos(parameters):\n",
    "        f = [f_multinomial_pos(i)(parameters) for i in range(len(parameters))]\n",
    "        f_i = f[label]\n",
    "        fprime = [-f_i*f_j for f_j in f]\n",
    "        fprime[label] = f_i*(1-f_i)\n",
    "        return fprime\n",
    "    return _fprime_multinomial_pos\n",
    "\n",
    "test_multinomial(f_multinomial_pos, fprime_multinomial_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test finished\n"
     ]
    }
   ],
   "source": [
    "def f_multinomial_log(label):\n",
    "    return (lambda parameters : parameters[label] - np.log(sum(np.exp(parameters))))\n",
    "\n",
    "def fprime_multinomial_log(label):\n",
    "    def _fprime_multinomial_log(parameters):\n",
    "        fprime = [-f_multinomial_pos(i)(parameters) for i in range(len(parameters))]\n",
    "        fprime[label] += 1\n",
    "        return fprime\n",
    "    return _fprime_multinomial_log\n",
    "    \n",
    "test_multinomial(f_multinomial_log, fprime_multinomial_log)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating the gradient\n",
    "The log likelihood of data point $i$ can be written as $L(\\Theta) = \\log P(Y_i, Z_i;\\Theta)$. \n",
    "So the gradient of log-likelihood function can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\partial_{\\Theta} L(\\Theta) = \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ll(parameters, data):\n",
    "    \"\"\"Compute the likelihood and its gradients.\n",
    "    \n",
    "    arguments:\n",
    "    parameters -- current value of parameters\n",
    "    data     -- values for all random variables\n",
    "    \"\"\"\n",
    "    p_n, p_m = parameters\n",
    "    likelihood = 0\n",
    "    grad_n = [0.0] * len(p_n)\n",
    "    grad_m = [0.0] * len(p_m)\n",
    "    for instance in data:\n",
    "        label, value = instance\n",
    "        likelihood += f_normal_log(value)(p_n)\n",
    "        grad_n += fprime_normal_log(value)(p_n)\n",
    "        likelihood += f_multinomial_log(label)(p_m)\n",
    "        grad_m += fprime_multinomial_log(label)(p_m)\n",
    "        \n",
    "    return likelihood, gradients\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
